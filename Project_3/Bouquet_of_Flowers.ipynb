{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project No. 3 - Bouquet of Flowers\n",
    "### Authors:\n",
    "M. Alejandro Villalobos C.\n",
    "Óscar Ruiz Ramirez\n",
    "Sofía Vargas Aceves\n",
    "### Fecha:\n",
    "24 de Marzo, 2022\n",
    "### Description:\n",
    "Tercer proyecto Machine Learning. Bouquet of Flowers Classification\n",
    "<br>Video disponible en: https://drive.google.com/file/d/16a9lxTxlBlv13Bh5LxRoAMB8-DwKilv2/view?usp=sharing\n",
    "<br>Dataset, csv y .ows en: https://drive.google.com/drive/folders/1oqmh6m7Xvt7Y1qrx2FHEz0nlC74QCSJE?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA READ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9',\n",
       "       ...\n",
       "       'n2044', 'n2045', 'n2046', 'n2047', 'category', 'image name', 'image',\n",
       "       'size', 'width', 'height'],\n",
       "      dtype='object', length=2054)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv(\"./Embedded_images.csv\")\n",
    "\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop(['image','image name', 'size', 'width','height'],axis=1)\n",
    "Dataset['category'] = Dataset['category'].replace(['Camelia', 'Dahlia', 'Hydrangea', 'Lilies', 'Orchids', 'Peony', 'Ranunculus', 'Roses', 'Sunflowers', 'Tulips'], [0,1,2,3,4,5,6,7,8,9])\n",
    "DataFrameFlowers = pd.DataFrame(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataFrameFlowers.drop(['category'], axis = 1)\n",
    "Y = DataFrameFlowers['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=50.0 / y_train.shape[0], penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "LR_better = LogisticRegression(C=50.0 / y_train.shape[0], penalty=\"l2\", solver=\"lbfgs\", tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.24875621890547264)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(X_train, y_train)\n",
    "LR_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictLR = LR.predict(X_test)\n",
    "y_predictLR_better = LR_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui haremos las variables especialmente para el modelo CNN, ya que se necesita estar en 3 dimensiones\n",
    "#Para training 201 x 2048 x 1, para test 51 x 2048 x 1\n",
    "X_trainCNN = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_testCNN = X_test.values.reshape(X_test.shape[0], X_test.shape[1] ,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "\n",
    "#Para coincidir tamaños, se convierten las etiquetas en \"one hot vectors\"\n",
    "y_trainCNN = keras.utils.to_categorical(np.asarray(y_train.factorize()[0]))\n",
    "y_testCNN = keras.utils.to_categorical(np.asarray(y_test.factorize()[0]))\n",
    "\n",
    "CNN = Sequential()\n",
    "CNN.add(Conv1D(128, 3, activation='relu', input_shape=(2048,1)))\n",
    "CNN.add(MaxPooling1D((2)))\n",
    "CNN.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN.add(MaxPooling1D((2)))\n",
    "CNN.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN.add(MaxPooling1D((2)))\n",
    "\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(256, activation='relu'))\n",
    "\n",
    "#Capa Dense tamaño 10 por las 10 categorizaciones finales\n",
    "CNN.add(Dense(10, activation='softmax'))\n",
    "\n",
    "CNN.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_better = Sequential()\n",
    "CNN_better.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(2048,1)))\n",
    "CNN_better.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "CNN_better.add(Dropout(0.7))\n",
    "CNN_better.add(MaxPooling1D(pool_size=2))\n",
    "CNN_better.add(Flatten())\n",
    "CNN_better.add(Dense(256, activation='relu'))\n",
    "\n",
    "#Capa Dense tamaño 10 por las 10 categorizaciones finales\n",
    "CNN_better.add(Dense(10, activation='softmax'))\n",
    "\n",
    "CNN_better.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainCNN.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 2s 285ms/step - loss: 2.8052 - accuracy: 0.1045 - val_loss: 2.3070 - val_accuracy: 0.1373\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 2s 262ms/step - loss: 2.2466 - accuracy: 0.1891 - val_loss: 2.2323 - val_accuracy: 0.1569\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 2s 259ms/step - loss: 1.9459 - accuracy: 0.3731 - val_loss: 2.1780 - val_accuracy: 0.3137\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 2s 257ms/step - loss: 1.4618 - accuracy: 0.5174 - val_loss: 2.2406 - val_accuracy: 0.3529\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 2s 256ms/step - loss: 0.8847 - accuracy: 0.7214 - val_loss: 3.4667 - val_accuracy: 0.2549\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 2s 279ms/step - loss: 0.4361 - accuracy: 0.8209 - val_loss: 3.4237 - val_accuracy: 0.4314\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 2s 265ms/step - loss: 0.3809 - accuracy: 0.8905 - val_loss: 4.2507 - val_accuracy: 0.3137\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 2s 248ms/step - loss: 0.1780 - accuracy: 0.9602 - val_loss: 4.3185 - val_accuracy: 0.2745\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 2s 250ms/step - loss: 0.1016 - accuracy: 0.9701 - val_loss: 5.5053 - val_accuracy: 0.2745\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 2s 255ms/step - loss: 0.0753 - accuracy: 0.9801 - val_loss: 6.1654 - val_accuracy: 0.2745\n"
     ]
    }
   ],
   "source": [
    "CNN_H = CNN.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 156ms/step - loss: 3.4883 - accuracy: 0.2090 - val_loss: 2.2394 - val_accuracy: 0.1961\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 2.1068 - accuracy: 0.3085 - val_loss: 2.1486 - val_accuracy: 0.2353\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 1.8411 - accuracy: 0.4826 - val_loss: 2.0929 - val_accuracy: 0.3725\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 152ms/step - loss: 1.2651 - accuracy: 0.7015 - val_loss: 2.1791 - val_accuracy: 0.4118\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.6391 - accuracy: 0.8259 - val_loss: 2.7298 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 0.3755 - accuracy: 0.8856 - val_loss: 3.5252 - val_accuracy: 0.2353\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 0.2971 - accuracy: 0.9005 - val_loss: 3.3977 - val_accuracy: 0.4118\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 0.1564 - accuracy: 0.9453 - val_loss: 3.5881 - val_accuracy: 0.3529\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 0.0784 - accuracy: 0.9751 - val_loss: 3.7466 - val_accuracy: 0.3529\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.0643 - accuracy: 0.9851 - val_loss: 4.0452 - val_accuracy: 0.3725\n"
     ]
    }
   ],
   "source": [
    "CNN_HBetter = CNN_better.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alex\\AppData\\Local\\Temp/ipykernel_22144/272496771.py:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "y_predictCNN = CNN.predict_classes(X_testCNN)\n",
    "y_predictCNN_better = CNN_better.predict_classes(X_testCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC(kernel='poly')\n",
    "SVM_better = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "SVM_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictSVM = SVM.predict(X_test)\n",
    "y_predictSVM_better = SVM_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=500)\n",
    "RFC_better = RandomForestClassifier(n_estimators= 400,bootstrap= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_features='sqrt', n_estimators=400)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.fit(X_train, y_train)\n",
    "RFC_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictRF = RFC.predict(X_test)\n",
    "y_predictRF_better = RFC_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Alex\\anaconda3\\envs\\ML_DL\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "CV_LR = cross_val_score(LR, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_LR_better = cross_val_score(LR_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_LR = accuracy_score(y_test,y_predictLR)\n",
    "AS_LR_better = accuracy_score(y_test,y_predictLR_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_SVM = cross_val_score(SVM, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_SVM_better = cross_val_score(SVM_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_SVM = accuracy_score(y_test,y_predictSVM)\n",
    "AS_SVM_better = accuracy_score(y_test,y_predictSVM_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_RF = cross_val_score(RFC, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_RF_better = cross_val_score(RFC_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_RF = accuracy_score(y_test,y_predictRF)\n",
    "AS_RF_better = accuracy_score(y_test,y_predictRF_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #5 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 53ms/step - loss: 0.0361 - accuracy: 0.9851\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.0540 - accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "CV_CNN = CNN.evaluate(X_trainCNN, y_trainCNN)\n",
    "CV_CNN_better = CNN_better.evaluate(X_trainCNN, y_trainCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 20ms/step - loss: 6.1654 - accuracy: 0.2745\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0452 - accuracy: 0.3725\n"
     ]
    }
   ],
   "source": [
    "AS_CNN = CNN.evaluate(X_testCNN, y_testCNN)\n",
    "AS_CNN_better = CNN_better.evaluate(X_testCNN, y_testCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_04418\">\n",
       "  <caption>Models' Accuracy Scores and Cross Validations</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04418_level0_col0\" class=\"col_heading level0 col0\" >Accuracy Scores</th>\n",
       "      <th id=\"T_04418_level0_col1\" class=\"col_heading level0 col1\" >CV AVG</th>\n",
       "      <th id=\"T_04418_level0_col2\" class=\"col_heading level0 col2\" >CV #1</th>\n",
       "      <th id=\"T_04418_level0_col3\" class=\"col_heading level0 col3\" >CV #2</th>\n",
       "      <th id=\"T_04418_level0_col4\" class=\"col_heading level0 col4\" >CV #3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row0\" class=\"row_heading level0 row0\" >LR</th>\n",
       "      <td id=\"T_04418_row0_col0\" class=\"data row0 col0\" >0.666667</td>\n",
       "      <td id=\"T_04418_row0_col1\" class=\"data row0 col1\" >0.597015</td>\n",
       "      <td id=\"T_04418_row0_col2\" class=\"data row0 col2\" >0.597015</td>\n",
       "      <td id=\"T_04418_row0_col3\" class=\"data row0 col3\" >0.686567</td>\n",
       "      <td id=\"T_04418_row0_col4\" class=\"data row0 col4\" >0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_04418_row1_col0\" class=\"data row1 col0\" >0.588235</td>\n",
       "      <td id=\"T_04418_row1_col1\" class=\"data row1 col1\" >0.716418</td>\n",
       "      <td id=\"T_04418_row1_col2\" class=\"data row1 col2\" >0.716418</td>\n",
       "      <td id=\"T_04418_row1_col3\" class=\"data row1 col3\" >0.716418</td>\n",
       "      <td id=\"T_04418_row1_col4\" class=\"data row1 col4\" >0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row2\" class=\"row_heading level0 row2\" >RF</th>\n",
       "      <td id=\"T_04418_row2_col0\" class=\"data row2 col0\" >0.647059</td>\n",
       "      <td id=\"T_04418_row2_col1\" class=\"data row2 col1\" >0.671642</td>\n",
       "      <td id=\"T_04418_row2_col2\" class=\"data row2 col2\" >0.671642</td>\n",
       "      <td id=\"T_04418_row2_col3\" class=\"data row2 col3\" >0.716418</td>\n",
       "      <td id=\"T_04418_row2_col4\" class=\"data row2 col4\" >0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row3\" class=\"row_heading level0 row3\" >CNN</th>\n",
       "      <td id=\"T_04418_row3_col0\" class=\"data row3 col0\" >0.274510</td>\n",
       "      <td id=\"T_04418_row3_col1\" class=\"data row3 col1\" >0.985075</td>\n",
       "      <td id=\"T_04418_row3_col2\" class=\"data row3 col2\" >0.985075</td>\n",
       "      <td id=\"T_04418_row3_col3\" class=\"data row3 col3\" >-</td>\n",
       "      <td id=\"T_04418_row3_col4\" class=\"data row3 col4\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row4\" class=\"row_heading level0 row4\" >LR_better</th>\n",
       "      <td id=\"T_04418_row4_col0\" class=\"data row4 col0\" >0.745098</td>\n",
       "      <td id=\"T_04418_row4_col1\" class=\"data row4 col1\" >0.716418</td>\n",
       "      <td id=\"T_04418_row4_col2\" class=\"data row4 col2\" >0.716418</td>\n",
       "      <td id=\"T_04418_row4_col3\" class=\"data row4 col3\" >0.731343</td>\n",
       "      <td id=\"T_04418_row4_col4\" class=\"data row4 col4\" >0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row5\" class=\"row_heading level0 row5\" >SVM_better</th>\n",
       "      <td id=\"T_04418_row5_col0\" class=\"data row5 col0\" >0.686275</td>\n",
       "      <td id=\"T_04418_row5_col1\" class=\"data row5 col1\" >0.746269</td>\n",
       "      <td id=\"T_04418_row5_col2\" class=\"data row5 col2\" >0.746269</td>\n",
       "      <td id=\"T_04418_row5_col3\" class=\"data row5 col3\" >0.746269</td>\n",
       "      <td id=\"T_04418_row5_col4\" class=\"data row5 col4\" >0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row6\" class=\"row_heading level0 row6\" >RF_better</th>\n",
       "      <td id=\"T_04418_row6_col0\" class=\"data row6 col0\" >0.764706</td>\n",
       "      <td id=\"T_04418_row6_col1\" class=\"data row6 col1\" >0.656716</td>\n",
       "      <td id=\"T_04418_row6_col2\" class=\"data row6 col2\" >0.656716</td>\n",
       "      <td id=\"T_04418_row6_col3\" class=\"data row6 col3\" >0.731343</td>\n",
       "      <td id=\"T_04418_row6_col4\" class=\"data row6 col4\" >0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_04418_level0_row7\" class=\"row_heading level0 row7\" >CNN_better</th>\n",
       "      <td id=\"T_04418_row7_col0\" class=\"data row7 col0\" >0.372549</td>\n",
       "      <td id=\"T_04418_row7_col1\" class=\"data row7 col1\" >0.985075</td>\n",
       "      <td id=\"T_04418_row7_col2\" class=\"data row7 col2\" >0.985075</td>\n",
       "      <td id=\"T_04418_row7_col3\" class=\"data row7 col3\" >-</td>\n",
       "      <td id=\"T_04418_row7_col4\" class=\"data row7 col4\" >-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22a5f8bff40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creación de dataframe con los resultados\n",
    "models = [\"LR\",\"SVM\", \"RF\", \"CNN\",\"LR_better\", \"SVM_better\", \"RF_better\", \"CNN_better\"]\n",
    "AS_values = [AS_LR, AS_SVM, AS_RF,  AS_CNN[1], AS_LR_better, AS_SVM_better, AS_RF_better, AS_CNN_better[1]]\n",
    "CV_values = [CV_LR, CV_SVM, CV_RF, [CV_CNN[1],'-','-'],CV_LR_better,CV_SVM_better, CV_RF_better, [CV_CNN_better[1],'-','-']]\n",
    "\n",
    "data = {\"Accuracy Scores\": AS_values, \"Cross Validations\": CV_values}\n",
    "df = pd.DataFrame(data, index = models)\n",
    "\n",
    "#Separación de arrays de Cross Validations en columnas\n",
    "dfCV = pd.DataFrame(df['Cross Validations'].to_list(), columns=['CV #1','CV #2','CV #3'], index = models)\n",
    "#Cálculo de promedio de Cross Validations\n",
    "dfCV.insert(0,'CV AVG', dfCV[['CV #1','CV #2','CV #3']].mean(axis=1, numeric_only=True))\n",
    "\n",
    "#Concatenación de dataframes con las columnas finales\n",
    "dfAcc = pd.concat([df['Accuracy Scores'], dfCV], axis=1)\n",
    "dfAcc = dfAcc.style.set_caption(\"Models' Accuracy Scores and Cross Validations\")\n",
    "dfAcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 1 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [1 0 4 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [1 0 2 1 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 3 0 0 1 2]\n",
      " [0 0 0 2 0 1 3 1 0 0]\n",
      " [0 0 0 0 0 0 1 8 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 0 1 0 4]]\n",
      "--------------------------------\n",
      "[[3 0 0 0 1 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 1 4 0 0 0 0 0]\n",
      " [1 0 0 0 0 5 0 0 0 1]\n",
      " [0 0 0 1 1 1 4 0 0 0]\n",
      " [0 0 0 1 0 0 2 5 0 1]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 1 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmLR=confusion_matrix(y_test,y_predictLR)\n",
    "print(cmLR)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "cmLR_better=confusion_matrix(y_test,y_predictLR_better)\n",
    "print(cmLR_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar en esta matriz de confusion que al sumar la cantidad de positivos, osea de los valores correctos que mostro (La diagonal) nos dio mayor cantidad el segundo modelo de logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 4 0 0 1 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 1 0 0 1 0]\n",
      " [0 0 1 0 1 1 0 1 0 3]\n",
      " [2 1 0 1 0 0 0 0 1 2]\n",
      " [4 2 0 2 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 1 0 0]\n",
      " [1 1 0 0 2 0 0 0 2 0]]\n",
      "--------------------------------\n",
      "[[0 1 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 1 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 3 0 0 0 0 4]\n",
      " [3 1 0 0 0 0 0 0 1 2]\n",
      " [3 1 0 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0]\n",
      " [1 1 0 0 4 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cmCNN=confusion_matrix(y_test,y_predictCNN)\n",
    "print(cmCNN)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "cmCNN_better=confusion_matrix(y_test,y_predictCNN_better)\n",
    "print(cmCNN_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las matrices de confusión de CNN se puede observar que no hubo muchas flores clasificadas correctamente, pues el accuracy de los modelos fue también bajo. No hubo mucha variación entre los resultados de cada una, puesto que su diagonal fue similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 1 0 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0 0]\n",
      " [1 0 4 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 1 4 0 0 0 0 0]\n",
      " [1 0 0 0 0 3 0 0 1 2]\n",
      " [0 0 0 2 0 1 3 1 0 0]\n",
      " [0 0 0 3 0 0 3 3 0 0]\n",
      " [0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0 0 1 0 4]]\n",
      "--------------------------------\n",
      "[[3 0 0 1 0 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0 0]\n",
      " [1 0 4 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 1 4 0 0 0 0 0]\n",
      " [1 0 0 0 0 5 0 0 0 1]\n",
      " [0 0 0 1 1 1 4 0 0 0]\n",
      " [0 0 0 3 0 0 3 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 1 0 5]]\n"
     ]
    }
   ],
   "source": [
    "cmSVM=confusion_matrix(y_test,y_predictSVM)\n",
    "print(cmSVM)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "cmSVM_better=confusion_matrix(y_test,y_predictSVM_better)\n",
    "print(cmSVM_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar en esta matriz de confusion que al sumar la cantidad de positivos, osea de los valores correctos que mostro (La diagonal) nos dio mayor cantidad el segundo modelo de Support Vector Machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 1 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 1 2 0 0 0 0 2]\n",
      " [1 0 0 0 0 3 0 0 1 2]\n",
      " [0 0 0 1 1 1 4 0 0 0]\n",
      " [0 0 0 1 0 0 2 5 0 1]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 1 0 0 4]]\n",
      "--------------------------------\n",
      "[[4 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 1 0 0 0 0 0]\n",
      " [0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 1 3 0 0 0 0 1]\n",
      " [1 0 0 0 0 3 0 0 1 2]\n",
      " [0 0 0 1 1 0 5 0 0 0]\n",
      " [0 0 0 1 0 0 1 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "cmRF=confusion_matrix(y_test,y_predictRF)\n",
    "print(cmRF)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "cmRF_better=confusion_matrix(y_test,y_predictRF_better)\n",
    "print(cmRF_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que Random Forest en ambos modelos clasificó correctamente la mayoría de los datos, aunque también se aprecia una mejora del primer al segundo modelo al tener menos valores fuera de la diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ¿Con qué tipo de flor se lograron los mejores resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best flower is: 7 with a score of 0.1568627450980392\n",
      "The best flower is: 5 with a score of 0.09803921568627452\n",
      "The best flower is: 2 with a score of 0.0784313725490196\n",
      "The best flower is: 2 with a score of 0.09803921568627451\n",
      "The best flower is: 2 with a score of 0.0784313725490196\n",
      "The best flower is: 5 with a score of 0.09803921568627452\n",
      "The best flower is: 7 with a score of 0.09803921568627452\n",
      "The best flower is: 7 with a score of 0.13725490196078433\n"
     ]
    }
   ],
   "source": [
    "def bestFlowerPerModel(cm):\n",
    "    diagonal = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        diagonal[i] = cm[i][i]\n",
    "\n",
    "    sumRow = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            sumRow[i] += cm[i][j]\n",
    "\n",
    "    avg = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        avg[i] = diagonal[i]/sumRow[i]\n",
    "\n",
    "    score = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        score[i] = avg[i]*(sumRow[i]/51)\n",
    "\n",
    "    highest = 0\n",
    "    pos = 0\n",
    "    for i in range(10):\n",
    "        if score[i] > highest:\n",
    "            highest = score[i]\n",
    "            pos = i\n",
    "\n",
    "    return \"The best flower is: \" + str(pos) + \" with a score of \" + str(highest)\n",
    "\n",
    "print(bestFlowerPerModel(cmLR))\n",
    "print(bestFlowerPerModel(cmLR_better))\n",
    "print(bestFlowerPerModel(cmCNN))\n",
    "print(bestFlowerPerModel(cmCNN_better))\n",
    "print(bestFlowerPerModel(cmSVM))\n",
    "print(bestFlowerPerModel(cmSVM_better))\n",
    "print(bestFlowerPerModel(cmRF))\n",
    "print(bestFlowerPerModel(cmRF_better))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Podemos observar que las flores mejor clasificadas fueron las Hydrangeas (2) y las Rosas (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ¿Cuál flor fue la mas difícil de clasificar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst flower is: 8 with a score of 0.058823529411764705\n",
      "The worst flower is: 8 with a score of 0.058823529411764705\n",
      "The worst flower is: 0 with a score of 0.0\n",
      "The worst flower is: 0 with a score of 0.0\n",
      "The worst flower is: 8 with a score of 0.058823529411764705\n",
      "The worst flower is: 8 with a score of 0.058823529411764705\n",
      "The worst flower is: 8 with a score of 0.058823529411764705\n",
      "The worst flower is: 8 with a score of 0.0784313725490196\n"
     ]
    }
   ],
   "source": [
    "def worstFlowerPerModel(cm):\n",
    "    diagonal = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        diagonal[i] = cm[i][i]\n",
    "\n",
    "    sumRow = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            sumRow[i] += cm[i][j]\n",
    "\n",
    "    avg = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        avg[i] = diagonal[i]/sumRow[i]\n",
    "\n",
    "    score = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(10):\n",
    "        score[i] = avg[i]*(sumRow[i]/51)\n",
    "\n",
    "    lowest = score[0]\n",
    "    pos = 0\n",
    "    for i in range(10):\n",
    "        if score[i] < lowest:\n",
    "            highest = score[i]\n",
    "            pos = i\n",
    "\n",
    "    return \"The worst flower is: \" + str(pos) + \" with a score of \" + str(lowest)\n",
    "\n",
    "print(worstFlowerPerModel(cmLR))\n",
    "print(worstFlowerPerModel(cmLR_better))\n",
    "print(worstFlowerPerModel(cmCNN))\n",
    "print(worstFlowerPerModel(cmCNN_better))\n",
    "print(worstFlowerPerModel(cmSVM))\n",
    "print(worstFlowerPerModel(cmSVM_better))\n",
    "print(worstFlowerPerModel(cmRF))\n",
    "print(worstFlowerPerModel(cmRF_better))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aquí vemos que la flor peor categorizada evidentemente fue el girasol (8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ¿Cuál modelo obtuvo los mejores resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9a0a3\">\n",
       "  <caption>Models' Accuracy Scores and Cross Validations</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9a0a3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy Scores</th>\n",
       "      <th id=\"T_9a0a3_level0_col1\" class=\"col_heading level0 col1\" >CV AVG</th>\n",
       "      <th id=\"T_9a0a3_level0_col2\" class=\"col_heading level0 col2\" >CV #1</th>\n",
       "      <th id=\"T_9a0a3_level0_col3\" class=\"col_heading level0 col3\" >CV #2</th>\n",
       "      <th id=\"T_9a0a3_level0_col4\" class=\"col_heading level0 col4\" >CV #3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row0\" class=\"row_heading level0 row0\" >LR</th>\n",
       "      <td id=\"T_9a0a3_row0_col0\" class=\"data row0 col0\" >0.666667</td>\n",
       "      <td id=\"T_9a0a3_row0_col1\" class=\"data row0 col1\" >0.597015</td>\n",
       "      <td id=\"T_9a0a3_row0_col2\" class=\"data row0 col2\" >0.597015</td>\n",
       "      <td id=\"T_9a0a3_row0_col3\" class=\"data row0 col3\" >0.686567</td>\n",
       "      <td id=\"T_9a0a3_row0_col4\" class=\"data row0 col4\" >0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_9a0a3_row1_col0\" class=\"data row1 col0\" >0.588235</td>\n",
       "      <td id=\"T_9a0a3_row1_col1\" class=\"data row1 col1\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row1_col2\" class=\"data row1 col2\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row1_col3\" class=\"data row1 col3\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row1_col4\" class=\"data row1 col4\" >0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row2\" class=\"row_heading level0 row2\" >RF</th>\n",
       "      <td id=\"T_9a0a3_row2_col0\" class=\"data row2 col0\" >0.647059</td>\n",
       "      <td id=\"T_9a0a3_row2_col1\" class=\"data row2 col1\" >0.671642</td>\n",
       "      <td id=\"T_9a0a3_row2_col2\" class=\"data row2 col2\" >0.671642</td>\n",
       "      <td id=\"T_9a0a3_row2_col3\" class=\"data row2 col3\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row2_col4\" class=\"data row2 col4\" >0.701493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row3\" class=\"row_heading level0 row3\" >CNN</th>\n",
       "      <td id=\"T_9a0a3_row3_col0\" class=\"data row3 col0\" >0.274510</td>\n",
       "      <td id=\"T_9a0a3_row3_col1\" class=\"data row3 col1\" >0.985075</td>\n",
       "      <td id=\"T_9a0a3_row3_col2\" class=\"data row3 col2\" >0.985075</td>\n",
       "      <td id=\"T_9a0a3_row3_col3\" class=\"data row3 col3\" >-</td>\n",
       "      <td id=\"T_9a0a3_row3_col4\" class=\"data row3 col4\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row4\" class=\"row_heading level0 row4\" >LR_better</th>\n",
       "      <td id=\"T_9a0a3_row4_col0\" class=\"data row4 col0\" >0.745098</td>\n",
       "      <td id=\"T_9a0a3_row4_col1\" class=\"data row4 col1\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row4_col2\" class=\"data row4 col2\" >0.716418</td>\n",
       "      <td id=\"T_9a0a3_row4_col3\" class=\"data row4 col3\" >0.731343</td>\n",
       "      <td id=\"T_9a0a3_row4_col4\" class=\"data row4 col4\" >0.761194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row5\" class=\"row_heading level0 row5\" >SVM_better</th>\n",
       "      <td id=\"T_9a0a3_row5_col0\" class=\"data row5 col0\" >0.686275</td>\n",
       "      <td id=\"T_9a0a3_row5_col1\" class=\"data row5 col1\" >0.746269</td>\n",
       "      <td id=\"T_9a0a3_row5_col2\" class=\"data row5 col2\" >0.746269</td>\n",
       "      <td id=\"T_9a0a3_row5_col3\" class=\"data row5 col3\" >0.746269</td>\n",
       "      <td id=\"T_9a0a3_row5_col4\" class=\"data row5 col4\" >0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row6\" class=\"row_heading level0 row6\" >RF_better</th>\n",
       "      <td id=\"T_9a0a3_row6_col0\" class=\"data row6 col0\" >0.764706</td>\n",
       "      <td id=\"T_9a0a3_row6_col1\" class=\"data row6 col1\" >0.656716</td>\n",
       "      <td id=\"T_9a0a3_row6_col2\" class=\"data row6 col2\" >0.656716</td>\n",
       "      <td id=\"T_9a0a3_row6_col3\" class=\"data row6 col3\" >0.731343</td>\n",
       "      <td id=\"T_9a0a3_row6_col4\" class=\"data row6 col4\" >0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9a0a3_level0_row7\" class=\"row_heading level0 row7\" >CNN_better</th>\n",
       "      <td id=\"T_9a0a3_row7_col0\" class=\"data row7 col0\" >0.372549</td>\n",
       "      <td id=\"T_9a0a3_row7_col1\" class=\"data row7 col1\" >0.985075</td>\n",
       "      <td id=\"T_9a0a3_row7_col2\" class=\"data row7 col2\" >0.985075</td>\n",
       "      <td id=\"T_9a0a3_row7_col3\" class=\"data row7 col3\" >-</td>\n",
       "      <td id=\"T_9a0a3_row7_col4\" class=\"data row7 col4\" >-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22a55de5940>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creación de dataframe con los resultados\n",
    "models = [\"LR\",\"SVM\", \"RF\", \"CNN\",\"LR_better\", \"SVM_better\", \"RF_better\", \"CNN_better\"]\n",
    "AS_values = [AS_LR, AS_SVM, AS_RF,  AS_CNN[1], AS_LR_better, AS_SVM_better, AS_RF_better, AS_CNN_better[1]]\n",
    "CV_values = [CV_LR, CV_SVM, CV_RF, [CV_CNN[1],'-','-'],CV_LR_better,CV_SVM_better, CV_RF_better, [CV_CNN_better[1],'-','-']]\n",
    "\n",
    "data = {\"Accuracy Scores\": AS_values, \"Cross Validations\": CV_values}\n",
    "df = pd.DataFrame(data, index = models)\n",
    "\n",
    "#Separación de arrays de Cross Validations en columnas, referenciando (10)\n",
    "dfCV = pd.DataFrame(df['Cross Validations'].to_list(), columns=['CV #1','CV #2','CV #3'], index = models)\n",
    "#Cálculo de promedio de Cross Validations\n",
    "dfCV.insert(0,'CV AVG', dfCV[['CV #1','CV #2','CV #3']].mean(axis=1, numeric_only=True))\n",
    "\n",
    "#Concatenación de dataframes con las columnas finales, referenciando (11)\n",
    "dfAcc = pd.concat([df['Accuracy Scores'], dfCV], axis=1)\n",
    "dfAcc = dfAcc.style.set_caption(\"Models' Accuracy Scores and Cross Validations\")\n",
    "dfAcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "El modelo con mejores resultados fue el RF_better\n",
    "En segundo tenemos a LR_better, con una diferencia muy pequeña"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ¿Cómo cree que pueda mejorar los resultados obtenidos?\n",
    "\n",
    "La mejor manera de mejorar nuestros resultados sería incrementar el tamaño de nuestro dataset, ya que tenemos muy pocos datos\n",
    "Otra manera de mejorar los resultados podría ser continuar ajustando los parámetros de los modelos hasta encontrar algunos que den resultados aun mejores, o incluso cambiar de modelos que se adapten más a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ¿Cómo varían los resultados entre el set de datos de entrenamiento y el de pruebas?\n",
    "\n",
    "En la mayoría de los modelos los resultados de entrenamiento y de pruebas son muy similares.\n",
    "Sin embargo, en el modelo de CNN observamos resultados de entrenamiento muy altos, pero en pruebas resultados muy bajos\n",
    "Esto nos indica que ocurrió overfitting, a pesar de que utilizamos dropout para intentar contrarrestar este efecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">_Se basó en apuntes de Regresión Lineal y teoría del curso para este proyecto._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Para todos los modelos excepto CNN_:\n",
    "<br>\n",
    "1. Cournapeau, D. (2021). scikit-learn, Machine Learning in Python. Retrieved from: https://scikit-learn.org/stable/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _Para CNN_:  \n",
    " \n",
    "2. Chollet, F. (2022). Clasificacion Básica: Predecir una imagen de moda. Retrieved from: https://www.tensorflow.org/tutorials/keras/classification?hl=es-419#hacer_predicciones\n",
    "\n",
    "3. TensorFlow. (2022). Red neuronal convolucional (CNN). Retrieved from: https://www.tensorflow.org/tutorials/images/cnn\n",
    "4. Ruizendaal, R. (2017).Deep Learning #3: More on CNNs & Handling Overfitting. Retrieved from: https://towardsdatascience.com/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d \n",
    "5. Brownlee, J. (2020). 1D Convolutional Neural Network Models for Human Activity Recognition. Retrieved from: https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Pandas. (2022). DataFrame. Retrieved from: https://pandas.pydata.org/docs/reference/frame.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "498cc7baa86d349c4936134328814e532a1d77a0c0949c12214c3e7da3053f05"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DeepEnvirom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
