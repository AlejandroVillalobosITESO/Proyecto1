{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project No. 4 - Mask Detection\n",
    "### Authors:\n",
    "M. Alejandro Villalobos C.\n",
    "Óscar Ruiz Ramirez\n",
    "Sofía Vargas Aceves\n",
    "### Fecha:\n",
    "14 de Abril, 2022\n",
    "### Description:\n",
    "Cuarto proyecto Machine Learning. Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9',\n",
       "       ...\n",
       "       'n2044', 'n2045', 'n2046', 'n2047', 'category', 'image name', 'image',\n",
       "       'size', 'width', 'height'],\n",
       "      dtype='object', length=2054)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv(\"./masks_detection.csv\")\n",
    "\n",
    "#Este dataset sera con las 3 fotos que hicimos para probar la AI\n",
    "DatasetTest = pd.read_csv(\"./test_mask.csv\")\n",
    "\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop(['image name', 'image','size', 'width', 'height'],axis=1)\n",
    "DatasetTest = DatasetTest.drop(['image name', 'image','size', 'width', 'height'],axis=1)\n",
    "DataFrame = pd.DataFrame(Dataset)\n",
    "DataFrameTest = pd.DataFrame(DatasetTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             n0        n1        n2        n3        n4        n5        n6  \\\n",
       "1845  0.099219  0.218688  0.081216  0.097855  0.109617  0.258140  0.027389   \n",
       "733   0.150905  0.276416  0.078415  0.526416  0.249105  0.680101  0.499007   \n",
       "1042  0.029721  0.194351  0.023086  0.123039  0.267416  0.197085  0.370767   \n",
       "629   0.524674  0.378981  0.425197  0.443407  0.751720  0.589656  0.338716   \n",
       "61    0.021106  0.069700  0.090646  0.631789  0.069943  0.677161  0.268689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1033  0.004787  0.075297  0.005737  0.373516  0.265485  0.536794  0.303763   \n",
       "1731  0.273692  0.308628  0.137522  0.131906  0.020834  0.236605  0.446002   \n",
       "763   0.033707  0.069336  0.215789  0.435256  0.020872  0.026404  0.457501   \n",
       "835   0.280853  0.214798  0.031541  0.109437  0.220826  0.321288  0.911428   \n",
       "1653  0.011068  0.263708  0.270939  0.017335  0.034326  0.280750  0.093825   \n",
       "\n",
       "            n7        n8        n9  ...     n2038     n2039     n2040  \\\n",
       "1845  0.060468  0.053276  0.391924  ...  0.006544  0.011880  0.154019   \n",
       "733   0.792445  0.247783  0.823956  ...  0.627328  0.584045  0.397540   \n",
       "1042  0.682531  0.254270  1.311792  ...  0.395593  0.037222  0.585946   \n",
       "629   0.609483  0.340905  0.632283  ...  0.446339  0.037747  0.487505   \n",
       "61    0.507709  0.499118  0.734241  ...  0.365034  0.351577  0.260382   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1033  0.254325  0.395956  0.657402  ...  0.602803  0.386929  0.030462   \n",
       "1731  0.273591  0.259212  0.677222  ...  0.116759  0.337748  0.601867   \n",
       "763   0.326230  0.126575  0.644051  ...  0.052362  0.018528  0.230118   \n",
       "835   0.416820  0.383386  0.170390  ...  0.439133  0.127258  0.033611   \n",
       "1653  0.095694  0.144248  0.804713  ...  0.093530  0.013426  0.100071   \n",
       "\n",
       "         n2041     n2042     n2043     n2044     n2045     n2046     n2047  \n",
       "1845  0.101234  0.101372  0.282761  0.445674  0.004976  0.141654  0.023634  \n",
       "733   1.474036  0.042375  0.142119  0.130712  0.602276  0.396587  0.231066  \n",
       "1042  0.837847  0.514111  0.435387  0.493128  0.020292  0.671329  0.335159  \n",
       "629   1.363306  0.047881  0.182597  0.108851  0.295738  0.156403  0.568126  \n",
       "61    1.383622  0.303306  0.085390  0.392143  0.094371  0.040292  0.414049  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1033  0.801656  0.066218  0.103235  0.206049  0.164521  0.076810  0.112484  \n",
       "1731  0.064075  0.239288  0.964444  0.607370  0.439907  0.483484  0.429982  \n",
       "763   1.484831  0.057684  1.466270  0.530786  0.052975  0.381096  0.067447  \n",
       "835   1.517158  0.221441  0.223245  0.000000  0.244325  0.184316  0.175723  \n",
       "1653  0.100860  0.039663  0.241803  0.106372  0.001087  0.491522  0.008696  \n",
       "\n",
       "[1670 rows x 2048 columns]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= DataFrame.drop(['category'],axis=1)\n",
    "Y = DataFrame['category']\n",
    "\n",
    "#Estos son con las 3 fotos que nosotros hicimos\n",
    "X_Our_test = DataFrameTest.drop(['category'],axis=1)\n",
    "y_Our_test = DataFrameTest['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=0)\n",
    "\n",
    "X_train.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "CLF = DecisionTreeClassifier(random_state=0,max_depth = 2000)\n",
    "CLF_more_depth = DecisionTreeClassifier(random_state=0,max_depth = 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3000, random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLF.fit(X_train,y_train)\n",
    "CLF_more_depth.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictCLF= CLF.predict(X_test)\n",
    "y_predictCLF_more_depth = CLF_more_depth.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=500)\n",
    "RFC_with_less_trees = RandomForestClassifier(n_estimators= 400,bootstrap= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, n_estimators=400)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.fit(X_train, y_train)\n",
    "RFC_with_less_trees.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictRF = RFC.predict(X_test)\n",
    "y_with_less_trees = RFC_with_less_trees.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Support Vector Machine (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC(C = 100.0 , kernel = 'linear')\n",
    "SVM2 = SVC(C = 25.0 , kernel = 'poly')\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=25.0, kernel='poly')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "SVM2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictSVM = SVM.predict(X_test)\n",
    "y_predictSVM2 = SVM2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes= (64,64,64,64))\n",
    "MLP2 = MLPClassifier(hidden_layer_sizes= (128,128,128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 128, 128, 128))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(X_train, y_train)\n",
    "MLP2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictMLP = MLP.predict(X_test)\n",
    "y_predictMLP2 = MLP2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88868941, 0.91382406, 0.90647482])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_CLF = cross_val_score(CLF, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_CLF_more_depth = cross_val_score(CLF_more_depth, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "\n",
    "CV_CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_CLF = accuracy_score(y_test,y_predictCLF)\n",
    "AS_CLF_more_depth = accuracy_score(y_test,y_predictCLF_more_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_RF = cross_val_score(RFC, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_RF_with_less_trees = cross_val_score(RFC_with_less_trees, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_RF = accuracy_score(y_test,y_predictRF)\n",
    "AS_RF_with_less_trees = accuracy_score(y_test,y_with_less_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3 Support Vector Machine (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_SVM = cross_val_score(SVM, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_SVM2 = cross_val_score(SVM2, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_SVM = accuracy_score(y_test,y_predictSVM)\n",
    "AS_SVM2 = accuracy_score(y_test,y_predictSVM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_MLP = cross_val_score(MLP, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_MLP2 = cross_val_score(MLP2, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_MLP = accuracy_score(y_test,y_predictMLP)\n",
    "AS_MLP2 = accuracy_score(y_test,y_predictMLP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_89062_\">\n",
       "  <caption>Models' Accuracy Scores and Cross Validations</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Accuracy Scores</th>\n",
       "      <th class=\"col_heading level0 col1\" >CV AVG</th>\n",
       "      <th class=\"col_heading level0 col2\" >CV #1</th>\n",
       "      <th class=\"col_heading level0 col3\" >CV #2</th>\n",
       "      <th class=\"col_heading level0 col4\" >CV #3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row0\" class=\"row_heading level0 row0\" >CLF</th>\n",
       "      <td id=\"T_89062_row0_col0\" class=\"data row0 col0\" >0.931564</td>\n",
       "      <td id=\"T_89062_row0_col1\" class=\"data row0 col1\" >0.902996</td>\n",
       "      <td id=\"T_89062_row0_col2\" class=\"data row0 col2\" >0.888689</td>\n",
       "      <td id=\"T_89062_row0_col3\" class=\"data row0 col3\" >0.913824</td>\n",
       "      <td id=\"T_89062_row0_col4\" class=\"data row0 col4\" >0.906475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row1\" class=\"row_heading level0 row1\" >SVM</th>\n",
       "      <td id=\"T_89062_row1_col0\" class=\"data row1 col0\" >0.977654</td>\n",
       "      <td id=\"T_89062_row1_col1\" class=\"data row1 col1\" >0.973653</td>\n",
       "      <td id=\"T_89062_row1_col2\" class=\"data row1 col2\" >0.969479</td>\n",
       "      <td id=\"T_89062_row1_col3\" class=\"data row1 col3\" >0.976661</td>\n",
       "      <td id=\"T_89062_row1_col4\" class=\"data row1 col4\" >0.974820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row2\" class=\"row_heading level0 row2\" >RF</th>\n",
       "      <td id=\"T_89062_row2_col0\" class=\"data row2 col0\" >0.970670</td>\n",
       "      <td id=\"T_89062_row2_col1\" class=\"data row2 col1\" >0.965271</td>\n",
       "      <td id=\"T_89062_row2_col2\" class=\"data row2 col2\" >0.967684</td>\n",
       "      <td id=\"T_89062_row2_col3\" class=\"data row2 col3\" >0.960503</td>\n",
       "      <td id=\"T_89062_row2_col4\" class=\"data row2 col4\" >0.967626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row3\" class=\"row_heading level0 row3\" >MLP</th>\n",
       "      <td id=\"T_89062_row3_col0\" class=\"data row3 col0\" >0.976257</td>\n",
       "      <td id=\"T_89062_row3_col1\" class=\"data row3 col1\" >0.974255</td>\n",
       "      <td id=\"T_89062_row3_col2\" class=\"data row3 col2\" >0.969479</td>\n",
       "      <td id=\"T_89062_row3_col3\" class=\"data row3 col3\" >0.973070</td>\n",
       "      <td id=\"T_89062_row3_col4\" class=\"data row3 col4\" >0.980216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row4\" class=\"row_heading level0 row4\" >CLF_more_depth</th>\n",
       "      <td id=\"T_89062_row4_col0\" class=\"data row4 col0\" >0.931564</td>\n",
       "      <td id=\"T_89062_row4_col1\" class=\"data row4 col1\" >0.902996</td>\n",
       "      <td id=\"T_89062_row4_col2\" class=\"data row4 col2\" >0.888689</td>\n",
       "      <td id=\"T_89062_row4_col3\" class=\"data row4 col3\" >0.913824</td>\n",
       "      <td id=\"T_89062_row4_col4\" class=\"data row4 col4\" >0.906475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row5\" class=\"row_heading level0 row5\" >SVM2</th>\n",
       "      <td id=\"T_89062_row5_col0\" class=\"data row5 col0\" >0.981844</td>\n",
       "      <td id=\"T_89062_row5_col1\" class=\"data row5 col1\" >0.972457</td>\n",
       "      <td id=\"T_89062_row5_col2\" class=\"data row5 col2\" >0.969479</td>\n",
       "      <td id=\"T_89062_row5_col3\" class=\"data row5 col3\" >0.973070</td>\n",
       "      <td id=\"T_89062_row5_col4\" class=\"data row5 col4\" >0.974820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row6\" class=\"row_heading level0 row6\" >RF_with_less_trees</th>\n",
       "      <td id=\"T_89062_row6_col0\" class=\"data row6 col0\" >0.973464</td>\n",
       "      <td id=\"T_89062_row6_col1\" class=\"data row6 col1\" >0.964671</td>\n",
       "      <td id=\"T_89062_row6_col2\" class=\"data row6 col2\" >0.964093</td>\n",
       "      <td id=\"T_89062_row6_col3\" class=\"data row6 col3\" >0.964093</td>\n",
       "      <td id=\"T_89062_row6_col4\" class=\"data row6 col4\" >0.965827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89062_level0_row7\" class=\"row_heading level0 row7\" >MLP2</th>\n",
       "      <td id=\"T_89062_row7_col0\" class=\"data row7 col0\" >0.980447</td>\n",
       "      <td id=\"T_89062_row7_col1\" class=\"data row7 col1\" >0.971860</td>\n",
       "      <td id=\"T_89062_row7_col2\" class=\"data row7 col2\" >0.969479</td>\n",
       "      <td id=\"T_89062_row7_col3\" class=\"data row7 col3\" >0.967684</td>\n",
       "      <td id=\"T_89062_row7_col4\" class=\"data row7 col4\" >0.978417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24eafa15088>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creación de dataframe con los resultados\n",
    "models = [\"CLF\",\"SVM\", \"RF\",\"MLP\", \"CLF_more_depth\", \"SVM2\", \"RF_with_less_trees\", \"MLP2\"]\n",
    "AS_values = [AS_CLF, AS_SVM, AS_RF,AS_MLP, AS_CLF_more_depth, AS_SVM2, AS_RF_with_less_trees,AS_MLP2]\n",
    "CV_values = [CV_CLF, CV_SVM, CV_RF,CV_MLP,CV_CLF_more_depth,CV_SVM2, CV_RF_with_less_trees,CV_MLP2]\n",
    "\n",
    "data = {\"Accuracy Scores\": AS_values, \"Cross Validations\": CV_values}\n",
    "df = pd.DataFrame(data, index = models)\n",
    "\n",
    "#Separación de arrays de Cross Validations en columnas\n",
    "dfCV = pd.DataFrame(df['Cross Validations'].to_list(), columns=['CV #1','CV #2','CV #3'], index = models)\n",
    "#Cálculo de promedio de Cross Validations\n",
    "dfCV.insert(0,'CV AVG', dfCV[['CV #1','CV #2','CV #3']].mean(axis=1, numeric_only=True))\n",
    "\n",
    "#Concatenación de dataframes con las columnas finales\n",
    "dfAcc = pd.concat([df['Accuracy Scores'], dfCV], axis=1)\n",
    "dfAcc = dfAcc.style.set_caption(\"Models' Accuracy Scores and Cross Validations\")\n",
    "dfAcc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casos prueba con nuestras fotos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el caso de CLF\n",
      "['no' 'yes' 'yes']\n",
      "Para el caso de RF\n",
      "['no' 'yes' 'yes']\n",
      "Para el caso de SVM\n",
      "['no' 'yes' 'yes']\n",
      "Para el caso de MLP\n",
      "['no' 'yes' 'yes']\n",
      "Y lo que se debio predecir:\n",
      "0     No\n",
      "1    Yes\n",
      "2    Yes\n",
      "Name: category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "predictionOursCLF = CLF.predict(X_Our_test)\n",
    "predictionOursRF = RFC.predict(X_Our_test)\n",
    "predictionOursSVM = SVM.predict(X_Our_test)\n",
    "predictionOursMLP = MLP.predict(X_Our_test)\n",
    "\n",
    "print(\"Para el caso de CLF\")\n",
    "print(predictionOursCLF)\n",
    "print(\"Para el caso de RF\")\n",
    "print(predictionOursRF)\n",
    "print(\"Para el caso de SVM\")\n",
    "print(predictionOursSVM)\n",
    "print(\"Para el caso de MLP\")\n",
    "print(predictionOursMLP)\n",
    "\n",
    "print(\"Y lo que se debio predecir:\")\n",
    "print(y_Our_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. ¿Cuál es el problema que se quiere resolver? ¿Qué preguntas esperaría contestar con \n",
    "el resultado?\n",
    "\n",
    "El problema que se requiere resolver, es que haya algun programa que al momento de que entre alguna persona en alguna tienda o empleo, cheque si traiga\n",
    "cubrebocas o no y a partir de eso, tomar alguna decision, ya sea activar alguna alarma para que no pueda entrar o se le avise a los de seguridad. Tambien servira para que se tenga una vigilancia constante de si se esta cumpliendo las reglas de seguridad de salud. Se esperaria que se tenga un programa que pueda responder facilmente que personas tengan cubreboca o no, sin importar raza, cultura o estilo que tenga la persona. Tambien responderia a la pregunta de cómo resolver una vigilancia dentro del lugar para que haya un cumplimiento de las reglas de seguridad de salud. Algunas de las preguntas que se esperan responder son: ¿Se puede detectar si tiene cubrebocas o no cualquier persona, sin importar raza, cultura o estilo?, ¿Se puede detectar si la persona tiene cubrebocas o no, sin importar el angulo en el que se encuentre la persona?, ¿Con nuestras fotos puede detectar si tenemos o no cubrebocas? ¿Es lo suficientemente eficiente para que se pueda usar en algun momento como vigilancia? \n",
    "\n",
    "B. ¿Qué datos son necesario y están disponibles para resolver el problema? ¿Existe un \n",
    "data set que se pueda utilizar? ¿Es factible generar y construir un data set? \n",
    "\n",
    "Los datos que seran necesarios, son fotos de personas con cubrebocas y sin cubrebocas, ya se tiene un dataset que se puede utilizar y que utilizamos para este proyecto (Un dataset de kaggle). Si seria factible generar un dataset, pero necesitariamos demasiadas personas distintas que nos mandaran fotos, y de distintas razas y culturas, por lo cual decidimos mejor usar uno de Kaggle que contiene muchas variantes.\n",
    "\n",
    "C. ¿Qué tipos de análisis espera realizar con los datos? \n",
    "\n",
    "Se espera no solo que el programa tenga un alto accuracy para los datos que se le de, sino que tambien se espera que al tener conocimiento del funcionamiento de todos los modelos, el modelo que más sirva para este tipo de dataset, sea el support vector machine, con una forma lineal, ya que solo se tiene 2 categorias y es más facil de manipular con este modelo. \n",
    "\n",
    "D. ¿Qué resultados se espera tener? ¿Cuál es el rendimiento mínimo que considera útil \n",
    "para su modelo? \n",
    "Se espera tener minimo un de 90% - 95% de cross validation, ya que solo se tiene dos categorias que se pueden clasificar. Y se espera que con fotos nuestras el programa pueda detectar con facilidad si se tiene cubrebocas o no, y a partir de eso saber si serviria para un empresa en un futuro para detectar a las personas con facilidad con una camara implementada. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "498cc7baa86d349c4936134328814e532a1d77a0c0949c12214c3e7da3053f05"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DeepEnvirom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
