{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project No. 5 -Marvel Heroes Project\n",
    "### Authors:\n",
    "M. Alejandro Villalobos C.\n",
    "Óscar Ruiz Ramirez\n",
    "Sofía Vargas Aceves\n",
    "### Fecha:\n",
    "12 de Mayo, 2022\n",
    "### Description:\n",
    "Quinto proyecto Machine Learning. Marvel Heroes Project\n",
    "<br>Video disponible en:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9',\n",
       "       ...\n",
       "       'n2044', 'n2045', 'n2046', 'n2047', 'category', 'image name', 'image',\n",
       "       'size', 'width', 'height'],\n",
       "      dtype='object', length=2054)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv(\"./Marvel_Heroes.csv\")\n",
    "\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             n0        n1        n2        n3        n4        n5        n6  \\\n",
       "0     0.274226  0.513062  0.197504  0.665105  0.330174  0.849714  0.341480   \n",
       "1     0.390927  0.156542  0.014353  0.274683  0.336344  0.535284  0.266266   \n",
       "2     0.445038  0.209385  0.088343  0.139893  0.219476  0.350784  0.111687   \n",
       "3     0.311281  0.071726  0.515384  0.215631  0.449452  0.273297  0.372235   \n",
       "4     0.832378  0.023829  0.348360  0.099742  0.198132  0.315028  0.144629   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1407  0.607610  0.206820  0.279536  0.749988  0.037422  0.683726  0.460102   \n",
       "1408  0.216671  0.224164  0.312867  0.378814  0.076853  0.633331  0.159525   \n",
       "1409  0.324099  0.128073  0.316498  0.281842  0.088786  0.272560  0.315466   \n",
       "1410  0.054855  0.094973  0.419886  0.315104  0.306649  0.845287  0.135354   \n",
       "1411  0.898068  0.433627  0.123856  0.393798  0.304222  0.643613  0.057624   \n",
       "\n",
       "            n7        n8        n9  ...     n2039     n2040     n2041  \\\n",
       "0     0.227035  0.447027  0.348300  ...  0.113479  0.143515  0.919633   \n",
       "1     0.112081  0.154997  0.240322  ...  0.342539  0.062376  0.472980   \n",
       "2     0.158394  0.394046  0.093597  ...  0.046520  0.002923  0.018524   \n",
       "3     0.221422  0.320879  0.688895  ...  0.097028  0.441283  0.287434   \n",
       "4     0.161208  0.151986  0.328818  ...  0.273553  0.064716  0.311113   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1407  0.021153  0.009352  0.133910  ...  0.612873  0.421482  1.315579   \n",
       "1408  0.277314  0.267354  0.227455  ...  0.660984  0.317678  0.183926   \n",
       "1409  0.147565  0.688583  0.373713  ...  0.521901  0.453730  0.498036   \n",
       "1410  0.158049  0.532958  0.460890  ...  0.388506  0.683312  0.371974   \n",
       "1411  0.045468  0.520864  0.805468  ...  0.317417  0.424889  0.301151   \n",
       "\n",
       "         n2042     n2043     n2044     n2045     n2046     n2047  category  \n",
       "0     0.501844  0.221359  0.143654  0.287712  0.940824  0.452115         0  \n",
       "1     0.083210  0.200632  0.000000  0.446124  0.114787  0.035318         0  \n",
       "2     0.162627  0.111622  0.050903  0.131569  0.460318  0.162004         0  \n",
       "3     0.664090  0.310156  0.080532  0.482015  0.615387  0.049985         0  \n",
       "4     0.211073  0.367244  0.216266  0.186792  0.296137  0.434543         0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1407  0.619510  0.068702  0.505099  0.057500  0.361412  0.484574        20  \n",
       "1408  0.203164  0.150677  0.353128  0.056985  0.512208  0.463051        20  \n",
       "1409  0.381122  0.161151  0.412052  0.193668  0.201227  0.038637        20  \n",
       "1410  0.726656  0.091185  0.104064  0.093930  0.096283  0.034724        20  \n",
       "1411  0.717223  0.008161  0.246946  0.021438  0.093104  0.003913        20  \n",
       "\n",
       "[1412 rows x 2049 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = Dataset.drop(['image name', 'image','size', 'width', 'height'],axis=1)\n",
    "Dataset['category'] = Dataset['category'].replace(['AntMan','BlackPanther', 'BlackWidow', 'CaptainAmerica', 'CaptainMarvel', 'Drax', 'DrStrange', 'Gamora', 'HawkEye', 'Hulk', 'Ironman', 'Loki', 'NickFury', 'Quake', 'ScarlettWitch', 'Spiderman', 'Thor', 'Valkyrie', 'Vision', 'WinterSoldier', 'Yondu'], [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "DataFrameMarvel = pd.DataFrame(Dataset)\n",
    "DataFrameMarvel.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = DataFrameMarvel.drop(['category'], axis = 1)\n",
    "Y = DataFrameMarvel['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "SVM = svm.SVC(kernel='poly',C=1, tol = 1e-6, cache_size= 200,probability=True)\n",
    "SVM_better = svm.SVC(C = 0.1, kernel='linear', tol = 1e-4,probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', probability=True, tol=0.0001)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "SVM_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictSVM = SVM.predict(X_test)\n",
    "y_predictSVM_better = SVM_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=500)\n",
    "RFC_better = RandomForestClassifier(n_estimators= 400,bootstrap= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, n_estimators=400)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.fit(X_train, y_train)\n",
    "RFC_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictRF = RFC.predict(X_test)\n",
    "y_predictRF_better = RFC_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #3 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes= (2008,2008))\n",
    "MLP2 = MLPClassifier(hidden_layer_sizes= (1024,1024,1024,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(1024, 1024, 1024, 1024))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(X_train, y_train)\n",
    "MLP2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictMLP = MLP.predict(X_test)\n",
    "y_predictMLP2 = MLP2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #4 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import keras\n",
    "import glob\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "paths = glob.glob('.//AugmentedDataset/*/*.jpg', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1481, 400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "dfList = []\n",
    "targets = []\n",
    "for img_path in paths:\n",
    "       img_name = img_path.split('\\\\')[-1].split('.')[0]\n",
    "       target = img_path.split('\\\\')[-2]\n",
    "\n",
    "       # read image\n",
    "       img = cv2.imread(img_path)\n",
    "       # save result\n",
    "       dfList.append(img)\n",
    "       targets.append(target)\n",
    "       #print(dfList)\n",
    "print(np.asarray(dfList).shape)\n",
    "\n",
    "#df = pd.DataFrame(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 20, 20, 20], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "dfT = pd.DataFrame(targets)\n",
    "dfT = encoder.fit_transform(dfT)\n",
    "MarvelChar = {index : label for index, label in enumerate(encoder.classes_)}\n",
    "\n",
    "Y = dfT.astype(object)\n",
    "Y #= np.asarray(targets).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = np.asarray(dfList).reshape(1481, 480000)\n",
    "X = pd.DataFrame(dfList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 12, 7, 8, 5, 3, 2, 0, 2, 9, 3, 5, 10, 3, 15, 3, 3, 13, 16, 1,\n",
       "       17, 17, 2, 2, 9, 10, 1, 10, 16, 2, 18, 2, 11, 9, 1, 3, 2, 16, 3,\n",
       "       12, 2, 9, 17, 5, 3, 3, 0, 2, 2, 5, 16, 9, 2, 5, 19, 2, 10, 11, 12,\n",
       "       11, 5, 11, 10, 18, 14, 9, 5, 10, 2, 18, 9, 3, 0, 16, 3, 15, 10, 2,\n",
       "       19, 13, 5, 0, 6, 3, 5, 0, 18, 5, 16, 1, 4, 15, 16, 10, 12, 2, 7, 7,\n",
       "       11, 2, 10, 11, 10, 3, 3, 16, 2, 2, 4, 16, 3, 4, 4, 16, 3, 1, 9, 10,\n",
       "       0, 16, 2, 10, 9, 13, 16, 3, 5, 15, 10, 0, 10, 0, 9, 10, 16, 3, 5,\n",
       "       15, 16, 13, 10, 2, 5, 2, 6, 3, 5, 6, 7, 2, 10, 2, 19, 2, 15, 17,\n",
       "       14, 2, 7, 2, 0, 7, 1, 19, 2, 2, 2, 15, 12, 3, 15, 13, 1, 3, 8, 11,\n",
       "       0, 5, 1, 2, 14, 19, 5, 12, 10, 4, 0, 3, 8, 15, 5, 15, 11, 2, 11,\n",
       "       11, 16, 13, 2, 16, 10, 3, 4, 5, 16, 12, 0, 2, 17, 1, 17, 8, 6, 9,\n",
       "       13, 18, 18, 10, 3, 2, 5, 10, 10, 2, 14, 11, 8, 12, 2, 10, 16, 3,\n",
       "       19, 10, 14, 10, 14, 2, 20, 3, 7, 19, 7, 9, 3, 3, 7, 5, 3, 3, 9, 4,\n",
       "       0, 15, 3, 15, 11, 20, 8, 15, 11, 2, 2, 6, 17, 3, 17, 10, 19, 15,\n",
       "       10, 18, 3, 16, 10, 0, 3, 7, 11, 3, 9, 9, 13, 9, 2, 5, 16, 0, 18,\n",
       "       15, 16, 9, 13, 20, 7, 12, 7], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Normalizando imagen de [0,1] para el modelo de CNN\n",
    "X_trainCNN = X_train/255.0\n",
    "X_testCNN = X_test/255.0\n",
    "\n",
    "#Aqui haremos las variables especialmente para el modelo CNN, ya que se necesita estar en 3 dimensiones\n",
    "#Para training 201 x 2048 x 1, para test 51 x 2048 x 1\n",
    "X_trainCNN = X_train.values.reshape(X_train.shape[0], img.shape[0], img.shape[0], 3)\n",
    "X_testCNN = X_test.values.reshape(X_test.shape[0], img.shape[0], img.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1184, 400, 400, 3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainCNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 400, 400, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testCNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainCNN = keras.utils.to_categorical(y_train)\n",
    "y_testCNN = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "CNN1 = Sequential()\n",
    "CNN2 = Sequential()\n",
    "CNN3 = Sequential()\n",
    "\n",
    "CNN1.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(img.shape[0],img.shape[0],3)))\n",
    "CNN1.add(MaxPooling2D(pool_size=2))\n",
    "CNN1.add(Dropout(0.25))\n",
    "CNN1.add(Flatten())\n",
    "CNN1.add(Dense(128, activation='relu'))\n",
    "CNN1.add(Dropout(0.5))\n",
    "CNN1.add(Dense(21, activation='softmax'))\n",
    "CNN1.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "CNN2.add(Conv2D(128, 3, activation='relu', input_shape=(img.shape[0],img.shape[0],3)))\n",
    "CNN2.add(MaxPooling2D(2))\n",
    "CNN2.add(Conv2D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling2D((2)))\n",
    "CNN2.add(Conv2D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling2D((2)))\n",
    "CNN2.add(Flatten())\n",
    "CNN2.add(Dense(256, activation='relu'))\n",
    "CNN2.add(Dense(10, activation='softmax'))\n",
    "CNN2.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "CNN3.add(Conv2D(filters=64, kernel_size=5, activation='relu', input_shape=(img.shape[0],img.shape[0],3)))\n",
    "CNN3.add(MaxPooling2D(pool_size=8))\n",
    "CNN3.add(Dropout(0.125))\n",
    "CNN3.add(Flatten())\n",
    "CNN3.add(Dense(64, activation='relu'))\n",
    "CNN3.add(Dropout(0.75))\n",
    "CNN3.add(Dense(21, activation='softmax'))\n",
    "CNN3.compile(optimizer='adam', loss = keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/37 [=======>......................] - ETA: 1:56 - loss: 7126.8047 - accuracy: 0.0656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22052/3760815458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCNN_H1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trainCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trainCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_testCNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_testCNN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programs\\Code\\anaconda3\\envs\\DeepEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CNN_H1 = CNN1.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_H2 = CNN2.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_H3 = CNN3.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictCNN = CNN1.predict_classes(X_testCNN)\n",
    "y_predictCNN2 = CNN2.predict_classes(X_testCNN)\n",
    "y_predictCNN3 = CNN3.predict_classes(X_testCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1404848484848485"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_SVM = cross_val_score(SVM, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_SVM_better = cross_val_score(SVM_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_SVM = accuracy_score(y_test,y_predictSVM)\n",
    "AS_SVM_better = accuracy_score(y_test,y_predictSVM_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22688\\1855073355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUC_RF\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRFC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAUC_RF_better\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predictRF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oscar\\anaconda3\\envs\\DeepEnvirom\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    558\u001b[0m             )\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[0;32m    562\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "CV_RF = cross_val_score(RFC, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_RF_better = cross_val_score(RFC_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_RF = accuracy_score(y_test,y_predictRF)\n",
    "AS_RF_better = accuracy_score(y_test,y_predictRF_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_MLP = cross_val_score(MLP, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_MLP2 = cross_val_score(MLP2, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_MLP = accuracy_score(y_test,y_predictMLP)\n",
    "AS_MLP2 = accuracy_score(y_test,y_predictMLP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #4 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_CNN1 = CNN1.evaluate(X_trainCNN, y_trainCNN)\n",
    "CV_CNN2 = CNN2.evaluate(X_trainCNN, y_trainCNN)\n",
    "CV_CNN3 = CNN3.evaluate(X_trainCNN, y_trainCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_CNN1 = CNN1.evaluate(X_testCNN, y_testCNN)\n",
    "AS_CNN2 = CNN2.evaluate(X_testCNN, y_testCNN)\n",
    "AS_CNN3 = CNN3.evaluate(X_testCNN, y_testCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de dataframe con los resultados\n",
    "models = [\"SVM\", \"RF\",\"MLP\", \"CNN\", \"SVM_better\", \"RF_better\", \"CNN2\", \"MLP2\", \"CNN3\"]\n",
    "AS_values = [AS_SVM, AS_RF,AS_MLP,  AS_CNN1, AS_SVM_better, AS_RF_better, AS_CNN2,AS_MLP2, AS_CNN3]\n",
    "CV_values = [CV_SVM, CV_RF,CV_MLP, [CV_CNN1,'-','-'],CV_SVM_better, CV_RF_better, [CV_CNN2[1],'-','-'],CV_MLP2,[CV_CNN3[1],'-','-']]\n",
    "\n",
    "data = {\"Accuracy Scores\": AS_values, \"Cross validation\": CV_values}\n",
    "df = pd.DataFrame(data, index = models)\n",
    "\n",
    "#Separación de arrays de cross validation en columnas\n",
    "dfCV = pd.DataFrame(df['Cross validation'].to_list(), columns=['CV #1','CV #2','CV #3'], index = models)\n",
    "#Cálculo de promedio de Area Under the Curve\n",
    "dfCV.insert(0,'CV AVG', dfCV[['CV #1','CV #2','CV #3']].mean(axis=1, numeric_only=True))\n",
    "\n",
    "#Concatenación de dataframes con las columnas finales\n",
    "dfAcc = pd.concat([df['Accuracy Scores'], dfCV], axis=1)\n",
    "dfAcc = dfAcc.style.set_caption(\"Models' Accuracy Scores and Cross validation\")\n",
    "dfAcc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9126be6fd62803567c103d473e49e4b3e11de01c18c12a7d39cc6956aa6bed8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DeepEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
