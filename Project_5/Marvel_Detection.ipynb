{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project No. 5 -Marvel Heroes Project\n",
    "### Authors:\n",
    "M. Alejandro Villalobos C.\n",
    "Óscar Ruiz Ramirez\n",
    "Sofía Vargas Aceves\n",
    "### Fecha:\n",
    "12 de Mayo, 2022\n",
    "### Description:\n",
    "Quinto proyecto Machine Learning. Marvel Heroes Project\n",
    "<br>Video disponible en:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9',\n",
       "       ...\n",
       "       'n2044', 'n2045', 'n2046', 'n2047', 'category', 'image name', 'image',\n",
       "       'size', 'width', 'height'],\n",
       "      dtype='object', length=2054)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv(\"./Marvel_Heroes.csv\")\n",
    "\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of             n0        n1        n2        n3        n4        n5        n6  \\\n",
       "0     0.274226  0.513062  0.197504  0.665105  0.330174  0.849714  0.341480   \n",
       "1     0.390927  0.156542  0.014353  0.274683  0.336344  0.535284  0.266266   \n",
       "2     0.445038  0.209385  0.088343  0.139893  0.219476  0.350784  0.111687   \n",
       "3     0.311281  0.071726  0.515384  0.215631  0.449452  0.273297  0.372235   \n",
       "4     0.832378  0.023829  0.348360  0.099742  0.198132  0.315028  0.144629   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1407  0.607610  0.206820  0.279536  0.749988  0.037422  0.683726  0.460102   \n",
       "1408  0.216671  0.224164  0.312867  0.378814  0.076853  0.633331  0.159525   \n",
       "1409  0.324099  0.128073  0.316498  0.281842  0.088786  0.272560  0.315466   \n",
       "1410  0.054855  0.094973  0.419886  0.315104  0.306649  0.845287  0.135354   \n",
       "1411  0.898068  0.433627  0.123856  0.393798  0.304222  0.643613  0.057624   \n",
       "\n",
       "            n7        n8        n9  ...     n2039     n2040     n2041  \\\n",
       "0     0.227035  0.447027  0.348300  ...  0.113479  0.143515  0.919633   \n",
       "1     0.112081  0.154997  0.240322  ...  0.342539  0.062376  0.472980   \n",
       "2     0.158394  0.394046  0.093597  ...  0.046520  0.002923  0.018524   \n",
       "3     0.221422  0.320879  0.688895  ...  0.097028  0.441283  0.287434   \n",
       "4     0.161208  0.151986  0.328818  ...  0.273553  0.064716  0.311113   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1407  0.021153  0.009352  0.133910  ...  0.612873  0.421482  1.315579   \n",
       "1408  0.277314  0.267354  0.227455  ...  0.660984  0.317678  0.183926   \n",
       "1409  0.147565  0.688583  0.373713  ...  0.521901  0.453730  0.498036   \n",
       "1410  0.158049  0.532958  0.460890  ...  0.388506  0.683312  0.371974   \n",
       "1411  0.045468  0.520864  0.805468  ...  0.317417  0.424889  0.301151   \n",
       "\n",
       "         n2042     n2043     n2044     n2045     n2046     n2047  category  \n",
       "0     0.501844  0.221359  0.143654  0.287712  0.940824  0.452115         0  \n",
       "1     0.083210  0.200632  0.000000  0.446124  0.114787  0.035318         0  \n",
       "2     0.162627  0.111622  0.050903  0.131569  0.460318  0.162004         0  \n",
       "3     0.664090  0.310156  0.080532  0.482015  0.615387  0.049985         0  \n",
       "4     0.211073  0.367244  0.216266  0.186792  0.296137  0.434543         0  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1407  0.619510  0.068702  0.505099  0.057500  0.361412  0.484574        20  \n",
       "1408  0.203164  0.150677  0.353128  0.056985  0.512208  0.463051        20  \n",
       "1409  0.381122  0.161151  0.412052  0.193668  0.201227  0.038637        20  \n",
       "1410  0.726656  0.091185  0.104064  0.093930  0.096283  0.034724        20  \n",
       "1411  0.717223  0.008161  0.246946  0.021438  0.093104  0.003913        20  \n",
       "\n",
       "[1412 rows x 2049 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = Dataset.drop(['image name', 'image','size', 'width', 'height'],axis=1)\n",
    "Dataset['category'] = Dataset['category'].replace(['AntMan','BlackPanther', 'BlackWidow', 'CaptainAmerica', 'CaptainMarvel', 'Drax', 'DrStrange', 'Gamora', 'HawkEye', 'Hulk', 'Ironman', 'Loki', 'NickFury', 'Quake', 'ScarlettWitch', 'Spiderman', 'Thor', 'Valkyrie', 'Vision', 'WinterSoldier', 'Yondu'], [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "DataFrameMarvel = pd.DataFrame(Dataset)\n",
    "DataFrameMarvel.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = DataFrameMarvel.drop(['category'], axis = 1)\n",
    "Y = DataFrameMarvel['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "SVM = svm.SVC(kernel='poly',C=1, tol = 1e-6, cache_size= 200,probability=True)\n",
    "SVM_better = svm.SVC(C = 0.1, kernel='linear', tol = 1e-4,probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, kernel='linear', probability=True, tol=0.0001)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "SVM_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictSVM = SVM.predict(X_test)\n",
    "y_predictSVM_better = SVM_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=500)\n",
    "RFC_better = RandomForestClassifier(n_estimators= 400,bootstrap= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, n_estimators=400)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.fit(X_train, y_train)\n",
    "RFC_better.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictRF = RFC.predict(X_test)\n",
    "y_predictRF_better = RFC_better.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #3 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes= (2008,2008))\n",
    "MLP2 = MLPClassifier(hidden_layer_sizes= (1024,1024,1024,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(1024, 1024, 1024, 1024))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(X_train, y_train)\n",
    "MLP2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predictMLP = MLP.predict(X_test)\n",
    "y_predictMLP2 = MLP2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model #4 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "CNN1 = Sequential()\n",
    "CNN2 = Sequential()\n",
    "CNN3 = Sequential()\n",
    "\n",
    "CNN1.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(2048,1)))\n",
    "CNN1.add(MaxPooling1D(pool_size=2))\n",
    "CNN1.add(Dropout(0.25))\n",
    "CNN1.add(Flatten())\n",
    "CNN1.add(Dense(128, activation='relu'))\n",
    "CNN1.add(Dropout(0.5))\n",
    "CNN1.add(Dense(21, activation='softmax'))\n",
    "\n",
    "CNN2.add(Conv1D(128, 3, activation='relu', input_shape=(2048,1)))\n",
    "CNN2.add(MaxPooling1D(2))\n",
    "CNN2.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling1D((2)))\n",
    "CNN2.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling1D((2)))\n",
    "CNN2.add(Flatten())\n",
    "CNN2.add(Dense(256, activation='relu'))\n",
    "CNN2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "CNN3.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(2048,1)))\n",
    "CNN3.add(MaxPooling1D(pool_size=8))\n",
    "CNN3.add(Dropout(0.125))\n",
    "CNN3.add(Flatten())\n",
    "CNN3.add(Dense(64, activation='relu'))\n",
    "CNN3.add(Dropout(0.75))\n",
    "CNN3.add(Dense(21, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_H1 = CNN1.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_H2 = CNN2.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_H3 = CNN3.fit(X_trainCNN, y_trainCNN, validation_data=(X_testCNN, y_testCNN), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prediction for New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictCNN = CNN1.predict_classes(X_testCNN)\n",
    "y_predictCNN2 = CNN2.predict_classes(X_testCNN)\n",
    "y_predictCNN3 = CNN3.predict_classes(X_testCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1404848484848485"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_SVM = cross_val_score(SVM, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_SVM_better = cross_val_score(SVM_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_SVM = accuracy_score(y_test,y_predictSVM)\n",
    "AS_SVM_better = accuracy_score(y_test,y_predictSVM_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22688\\1855073355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mAUC_RF\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRFC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mAUC_RF_better\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_predictRF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\oscar\\anaconda3\\envs\\DeepEnvirom\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    558\u001b[0m             )\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[0;32m    562\u001b[0m             \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "CV_RF = cross_val_score(RFC, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_RF_better = cross_val_score(RFC_better, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_RF = accuracy_score(y_test,y_predictRF)\n",
    "AS_RF_better = accuracy_score(y_test,y_predictRF_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 Neural Network: MultiLayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_MLP = cross_val_score(MLP, X_train, y_train, cv=3, scoring = \"accuracy\")\n",
    "CV_MLP2 = cross_val_score(MLP2, X_train, y_train, cv=3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_MLP = accuracy_score(y_test,y_predictMLP)\n",
    "AS_MLP2 = accuracy_score(y_test,y_predictMLP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #4 Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_CNN1 = CNN1.evaluate(X_trainCNN, y_trainCNN)\n",
    "CV_CNN2 = CNN2.evaluate(X_trainCNN, y_trainCNN)\n",
    "CV_CNN3 = CNN3.evaluate(X_trainCNN, y_trainCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_CNN1 = CNN1.evaluate(X_testCNN, y_testCNN)\n",
    "AS_CNN2 = CNN2.evaluate(X_testCNN, y_testCNN)\n",
    "AS_CNN3 = CNN3.evaluate(X_testCNN, y_testCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de dataframe con los resultados\n",
    "#models = [\"SVM\", \"RF\",\"MLP\", \"CNN\", \"SVM_better\", \"RF_better\", \"CNN2\", \"MLP2\", \"CNN3\"]\n",
    "#AS_values = [AS_SVM, AS_RF,AS_MLP,  AS_CNN1, AS_SVM_better, AS_RF_better, AS_CNN2,AS_MLP2, AS_CNN3]\n",
    "#CV_values = [CV_SVM, CV_RF,CV_MLP, [CV_CNN1,'-','-'],CV_SVM_better, CV_RF_better, [CV_CNN2[1],'-','-'],CV_MLP2,[CV_CNN3[1],'-','-']]\n",
    "\n",
    "models = [\"SVM\", \"RF\",\"MLP\", \"CNN\", \"SVM_better\", \"RF_better\", \"CNN2\", \"MLP2\", \"CNN3\"]\n",
    "AS_values = [AS_SVM, AS_RF,AS_MLP, AS_SVM_better, AS_RF_better,AS_MLP2]\n",
    "CV_values = [CV_SVM, CV_RF,CV_MLP,CV_SVM_better, CV_RF_better,CV_MLP2]\n",
    "\n",
    "data = {\"Accuracy Scores\": AS_values, \"Cross validation\": CV_values}\n",
    "df = pd.DataFrame(data, index = models)\n",
    "\n",
    "#Separación de arrays de cross validation en columnas\n",
    "dfCV = pd.DataFrame(df['Cross validation'].to_list(), columns=['CV #1','CV #2','CV #3'], index = models)\n",
    "#Cálculo de promedio de Area Under the Curve\n",
    "dfCV.insert(0,'CV AVG', dfCV[['CV #1','CV #2','CV #3']].mean(axis=1, numeric_only=True))\n",
    "\n",
    "#Concatenación de dataframes con las columnas finales\n",
    "dfAcc = pd.concat([df['Accuracy Scores'], dfCV], axis=1)\n",
    "dfAcc = dfAcc.style.set_caption(\"Models' Accuracy Scores and Cross validation\")\n",
    "dfAcc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e81ddef9c506a7392a49d5798d0636d138ad487f83abc805786e6ee1f68ca88"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DeepEnvirom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
