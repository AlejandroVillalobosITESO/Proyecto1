{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project No. 5 -Marvel Heroes Project\n",
    "### Authors:\n",
    "M. Alejandro Villalobos C.\n",
    "Óscar Ruiz Ramirez\n",
    "Sofía Vargas Aceves\n",
    "### Fecha:\n",
    "12 de Mayo, 2022\n",
    "### Description:\n",
    "Quinto proyecto Machine Learning. Marvel Heroes Project\n",
    "<br>Video disponible en:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9',\n",
       "       ...\n",
       "       'n2044', 'n2045', 'n2046', 'n2047', 'category', 'image name', 'image',\n",
       "       'size', 'width', 'height'],\n",
       "      dtype='object', length=2054)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset = pd.read_csv(\"./Marvel_Heroes.csv\")\n",
    "\n",
    "Dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dataset = Dataset.drop(['image name', 'image','size', 'width', 'height'],axis=1)\n",
    "#Dataset['category'] = Dataset['category'].replace(['AntMan','BlackPanther', 'BlackWidow', 'CaptainAmerica', 'CaptainMarvel', 'Drax', 'Dr.Strange', 'Gamora', 'HawkEye', 'Hulk', 'Ironman', 'Loki', 'NickFury', 'Quake', 'ScarlettWitch', 'Spiderman', 'Thor', 'Valkyrie', 'Vision', 'WinterSoldier', 'Yondu'], [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "DataFrameMarvel = pd.DataFrame(Dataset)\n",
    "DataFrameMarvel.info"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = DataFrameMarvel.drop(['category'], axis = 1)\n",
    "Y = DataFrameMarvel['category']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model #1 Support Vector Machine (SVM)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Model Creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "SVM = svm.SVC(kernel='poly',C=1, tol = 1e-6, cache_size= 200)\n",
    "SVM_better = svm.SVC(C = 0.1, kernel='linear', tol = 1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SVM.fit(X_train, y_train)\n",
    "SVM_better.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Prediction for New Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predictSVM = SVM.predict(X_test)\n",
    "y_predictSVM_better = SVM_better.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model #2 Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Model Creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=500)\n",
    "RFC_better = RandomForestClassifier(n_estimators= 400,bootstrap= False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RFC.fit(X_train, y_train)\n",
    "RFC_better.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Prediction for New Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predictRF = RFC.predict(X_test)\n",
    "y_predictRF_better = RFC_better.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model #3 Neural Network: MultiLayer Perceptron (MLP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Model Creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "MLP = MLPClassifier(hidden_layer_sizes= (2008,2008))\n",
    "MLP2 = MLPClassifier(hidden_layer_sizes= (1024,1024,1024,1024))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Training: Adjust Model with Historic Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MLP.fit(X_train, y_train)\n",
    "MLP2.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Prediction for New Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_predictMLP = MLP.predict(X_test)\n",
    "y_predictMLP2 = MLP2.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model #4 Convolutional Neural Network (CNN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Model Creation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "CNN1 = Sequential()\n",
    "CNN2 = Sequential()\n",
    "CNN3 = Sequential()\n",
    "\n",
    "CNN1.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(2048,1)))\n",
    "CNN1.add(MaxPooling1D(pool_size=2))\n",
    "CNN1.add(Dropout(0.25))\n",
    "CNN1.add(Flatten())\n",
    "CNN1.add(Dense(128, activation='relu'))\n",
    "CNN1.add(Dropout(0.5))\n",
    "CNN1.add(Dense(21, activation='softmax'))\n",
    "\n",
    "CNN2.add(Conv1D(128, 3, activation='relu', input_shape=(2048,1)))\n",
    "CNN2.add(MaxPooling1D(2))\n",
    "CNN2.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling1D((2)))\n",
    "CNN2.add(Conv1D(256, 3, activation='relu'))\n",
    "CNN2.add(MaxPooling1D((2)))\n",
    "CNN2.add(Flatten())\n",
    "CNN2.add(Dense(256, activation='relu'))\n",
    "CNN2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "CNN3.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(2048,1)))\n",
    "CNN3.add(MaxPooling1D(pool_size=8))\n",
    "CNN3.add(Dropout(0.125))\n",
    "CNN3.add(Flatten())\n",
    "CNN3.add(Dense(64, activation='relu'))\n",
    "CNN3.add(Dropout(0.75))\n",
    "CNN3.add(Dense(21, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e81ddef9c506a7392a49d5798d0636d138ad487f83abc805786e6ee1f68ca88"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DeepEnvirom')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}